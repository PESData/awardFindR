---
title: "sources"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{sources}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Because each source is served in a unique way and often requires complex looping, routines are associated with each. At the top level, all should return data.frames of keyword specified, date delimited searches, retaining as much potentially relevant information about each result as possible.

Different grant databases are handled through two different routines, depending on which level we are running our keyword query. The best way to get results is through the `awardsBot()` routine which returns a standardized data.frame that integrates multiple sources. If one is interested in the nuances of a specific data source, however, these functions provide lower-level access to the raw data returned from one specific source.

## NSF

The NSF API implementation loops through API calls until it's collected all the results for a keyword-date combo. All activity is handled by the `nsf_get()` routine. To get a raw NSF data.frame, we would run

```
nsf <- nsf_get(query="keyword", from="2015-01-01", to="2020-01-01")
```

Like the Federal Reporter, because of the nature of the API, the direct query function only handles one keyword at a time. Multiple keywords are handled at a higher level.

# Federal Reporter

Like NSF, the Federal Reporter implementation loops through API calls until there are no more results for a specific keyword-date combo. The Federal Reporter API provides a number of sources, including NIH and IES. The `agency` parameter of `fedreporter_get()` is free-form and theoretically can include any agency that the Federal Reporter holds data for, though the `awardsBot()` routine only ever uses "nih" or "ies" as values. All activity is handled by the `fedreporter_get()` routine.

```
nih <- fedreporter_get(query="keyword", from=2015, to=2020, agency="nih")
```

Like NSF, because of the nature of the API, the direct query function only handles one keyword at a time. Multiple keywords are handled at a higher level.

# NEH

NEH provides all their grants in a single csv file, making this source the simplest implementation of all. `neh_get()` integrates fetching the most recent csv file from the internet and looping keyword queries through it. To directly query the NEH database for mulitple keywords over the past two years, for example, we could run the following:
```
neh <- neh_get(c("focus groups", "ethnography"), 2018, 2020)
```

# Sloan

Sloan querying is mainly implemented through one big HTML scrape. The Sloan website and its search function are really not tailored to usage like an API. It's simpler to grab the entire database at once and process it through a bunch of xpath queries afterward. The right http request will return all possible results. The `sloan_df()` function runs through this whole process, and returns a data.frame. 

The `sloan_df()` function can be run independently to construct the a full data.frame of all awards from their website, like so

```
sloan <- sloan_df()
```

We can construct and query the Sloan database in one command, as so:
```
sloan_results <- sloan_get(c("case studies", "qualitative data",), 2018, 2020)
```
